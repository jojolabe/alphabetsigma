---
title: 'Escola ISIS de Radicalização Religiosa: Uma Análise com NLP'
author: 'João Pedro Oliveira'
date: '2020-04-22'
slug: isis-nlp-analysis
categories: [nlp, LDA, dificuldade intermediária]
tags: []
lastmod: '2020-04-22T19:35:15-03:00'
layout: post
type: post
highlight: yes
description: 'Nessa publicação aplico o modelo LDA em um dataset que contém artigos de revista utilizados pelo Estado Islâmico em sua propaganda política.'
---



<p>Nesse post nós iremos fazer uma simples (e rápida) análise do dataset “ISIS Religious Texts v1”, que pode ser encontrado <a href="https://www.kaggle.com/fifthtribe/isis-religious-texts">AQUI</a>. Essa base de dados contém textos de duas revistas do ISIS, estas sendo a “Dabiq” e a “Rumyiah”, que são (ou eram?) usadas para propaganda política e recrutamento de novos membros para o grupo terrorista.</p>
<p>Primeiro começamos carregando as bibliotecas essenciais para a tarefa, com atenção à Rlang, que nos será bem util. Você pode conferir melhor suas funcionalidades nessa publicação <a href="https://www.tidyverse.org/blog/2018/03/rlang-0.2.0/">AQUI (em inglês)</a>, feita pelo time de desenvolvedores do Tidyverse.</p>
<pre class="r"><code>library(tidyverse) # É uma meta-biblioteca, isto é, uma bib. que contém outras bibliotecas.
library(tm) # Text mining no geral, faz de tudo um pouco.
library(topicmodels) # Para criar o modelo LDA.
library(tidytext) # Ferramentas de tidy NLP.
library(SnowballC) # Para o stemming!
library(magrittr) # NEW TOOLS!
library(rlang)
library(forcats)</code></pre>
<p>Então vamos carregar os dados na memória, usando o <code>{readr}</code>, que já vem incluso na meta-biblioteca <code>{tidyverse}</code>. Contudo, para evitar problemas de compatibilidade de caracteres, visto que podemos ter texto em árabe, já me antecipo e altero o <a href="https://en.wikipedia.org/wiki/Character_encoding">encoding</a> da coluna que contém o texto para UTF-8, que é o ideal para as bibliotecas de análise de texto que serão usadas (especialmente a <code>{tm}</code>). Em diversas situações, podem ocorrer erros durante a análise devido ao texto estar no encoding errado, a alteração deste – embora tenha um motivo claro, e preventivo, neste dataset – pode ser útil em outros contextos também.</p>
<pre class="r"><code>dataset = readr::read_csv(&#39;../../data/ISIS Religious Texts v1.csv&#39;) # Carrega os dados

dataset$Quote = iconv(dataset$Quote, &quot;ASCII&quot;, &quot;UTF-8&quot;, sub=&quot;byte&quot;) # Altera o encoding

head(dataset)</code></pre>
<pre><code>## # A tibble: 6 x 8
##   Magazine Issue Date   Type  Source   Quote           Purpose `Article Name`   
##   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;           &lt;chr&gt;   &lt;chr&gt;            
## 1 Dabiq        1 Jun-14 Jiha… Abu Mus… The spark has … Support First Page       
## 2 Dabiq        1 Jun-14 Hadi… Sahih M… &lt;93&gt;The Hour w… Support Introduction     
## 3 Dabiq        1 Jun-14 Jiha… Abu Mus… &lt;93&gt;The spark … Support Introduction     
## 4 Dabiq        1 Jun-14 Jiha… Abu Bak… &lt;93&gt;O Muslims … Support Khilafah Declared
## 5 Dabiq        1 Jun-14 Jiha… Abu Bak… &lt;93&gt;O Ummah of… Support The World has Di…
## 6 Dabiq        1 Jun-14 Jiha… Abu Bak… &lt;93&gt;Therefore,… Support A Call to Hijrah</code></pre>
<p>Ao observar o dataset vemos que ele possui 8 colunas e aproximadamente 2.700 linhas. Informações como data (2014-2016), revista, tipo e propósito são insumos valiosos, e não serão usadas aqui para mantermos esta publicação em um tamanho restrito. Uma ideia que não será abordada nessa publicação é observarmos se há alteração do discurso conforme a situação política do ISIS se agrava, será que o tom passou a ser mais messiânico? Não sei, fica o exercicio ao leitor.</p>
<p>Enfim, passemos ao código…</p>
<p>Como sempre começamos com uma função, dessa vez crio uma chamada <code>cleaner_impurities</code>, o que ela faz é simples. Ela passa o texto pela função <code>stringr::str_replace_all()</code>, que substitui um elemento expresso por meio de expressão regular, por outro. No código abaixo, entra texto, que é passado pela função anteriormente descrita, e então retornado sem pontuação, com um espaço no lugar.</p>
<pre class="r"><code>cleaner_impurities = function(text){
  text %&gt;% 
    stringr::str_replace_all(&quot;[[:punct:]]&quot;, &quot; &quot;) 
  text
}</code></pre>
<p>Mas calma… Você, pessoa bonita e atenta, poderia me chamar atenção ao fato de que existe a função <code>tm::map(removePunctuation)</code>, que ao passarmos no <a href="https://en.wikipedia.org/wiki/Text_corpus">Corpus</a> atinge o mesmo objetivo. Concordo, mas estava afim de brincar com o <code>rlang</code>, e também, a função também dá uma utilidade às <a href="https://alphabetsigma.netlify.app/2020/03/17/introducao-as-expressoes-regulares/">expressões regulares, que vimos no post anterior</a>.</p>
<pre class="r"><code>treat = function(data, texto_col= Quote){
  
 data %&gt;%
    mutate({{ texto_col }} := cleaner_impurities({{ texto_col }})) %&gt;% 
    pull({{ texto_col }}) -&gt; data_res
  
  data_res
}</code></pre>
<p>A sintaxe da função acima pode ser um pouco nova para alguns, os operadores <code>{{ }}</code> (lê-se Curly-Curly) e <code>:=</code> nos permitem utilizarmos os nomes das colunas dos dataframes como argumentos, sem precisarmos recorrer a construções de código obscuras, como é possível ver nesta <a href="https://www.brodrigues.co/blog/2019-06-20-tidy_eval_saga/">publicação do Bruno Rodrigues, em seu blog</a>.</p>
<p>Mas, o que essa função faz é bem simples. A função aceita dois argumentos, <code>data</code> e <code>texto_col</code>, a primeira corresponde ao data.frame/tibble que contém os dados a serem tratados, a última corresponde ao nome da coluna qual está o texto desejado. Altera a coluna ‘Quote’, passando-a pela função <code>cleaner_impurities</code>, e então retorna ela como um <strong>vetor</strong>.</p>
<p>Preste atenção ao fato de que a informação do nome da coluna não deve ser inserida como uma <code>'string'</code>, e sim como se fosse um <code>objeto</code>, <a href="https://stackoverflow.com/questions/61377657/tidy-evaluation-not-working-with-mutate-and-stringr">caso contrário, teremos um resultado inesperado</a>.</p>
<pre class="r"><code>topTerms = function(text, n_topics=3){
  
   text %&gt;%
    SnowballC::wordStem(language= &#39;english&#39;) %&gt;% 
    tm::VectorSource() %&gt;% # Interpreta cada vetor como um documento.
    tm::Corpus() %&gt;%  # Cria um corpus com os documentos
    tm::tm_map(tolower) %&gt;%  # Transforma todos os documentos em letras minusculas
    tm::tm_map(removePunctuation) %&gt;% 
    tm::tm_map(removeNumbers) %&gt;% # Remove os números
    tm::tm_map(removeWords, stopwords(&#39;english&#39;)) %&gt;% # Remove palavras frequentes e que são vazias de significado (the, it, as, etc.)
    tm::DocumentTermMatrix() -&gt; DTM # Transforma em uma Document Term Matrix.
  
  indices_unicos &lt;- unique(DTM$i) # index de cada valor único.
  DTM &lt;- DTM[indices_unicos, ] # pega um subset desses indexs
  
  topterms &lt;- topicmodels::LDA(DTM, k = n_topics) %&gt;%  #Roda o LDA com 3 tópicos
    tidytext::tidy(matrix= &#39;beta&#39;) %&gt;% # Transforma o resultado do modelo em um objeto &#39;tidy&#39;, manipulável.
    group_by(topic) %&gt;% 
    top_n(20, beta) %&gt;% # Seleciona os 15 maiores betas.
    ungroup %&gt;% 
    arrange(topic, -beta)
  
  topterms # Retorna.

}

res = dataset %&gt;% 
  treat() %&gt;% 
  topTerms()

    
res</code></pre>
<pre><code>## # A tibble: 60 x 3
##    topic term         beta
##    &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;
##  1     1 allah     0.0581 
##  2     1 will      0.0240 
##  3     1 said      0.0158 
##  4     1 indeed    0.0117 
##  5     1 people    0.0114 
##  6     1 upon      0.00826
##  7     1 one       0.00749
##  8     1 messenger 0.00748
##  9     1 lord      0.00745
## 10     1 say       0.00685
## # … with 50 more rows</code></pre>
<p>O trecho acima é bem auto-explicativo, até mesmo devido aos comentários no código. Informações extras podem ser encontradas na documentação das funções.</p>
<p>Vamos plotar as informações que conseguimos, assim é possível visualizarmos melhor o resultado.</p>
<pre class="r"><code> plt = res %&gt;% # take the top terms
          mutate(term = reorder(term, beta)) %&gt;%
          ggplot(aes(term, beta, fill = factor(topic))) + 
          geom_col(show.legend = FALSE) + 
          facet_wrap(~ topic, scales = &quot;free&quot;) + 
          labs(x = NULL, y = &quot;Beta&quot;) +  
          coord_flip()
  
plt</code></pre>
<p><img src="/post/2020-04-22-escola-isis-de-radicalizacao-religiosa-uma-analise-com-nlp_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Como esperado, temos quatro grupos, porém, ainda temos muita poluição nos dados. Irei adicionar alguns passos adicionais, e tentaremos ter um resultado mais limpo.</p>
<pre class="r"><code>cleaned_docs = function(data){
  data %&gt;% 
    pull({{ Quote }}) %&gt;% 
    cleaner_impurities %&gt;% 
    VectorSource() %&gt;% 
    Corpus() %&gt;% 
    DocumentTermMatrix() %&gt;% 
    tidy() %&gt;% 
    anti_join(stop_words, by = c(&#39;term&#39;= &#39;word&#39;)) %&gt;% 
    group_by(document) %&gt;% 
    mutate(terms = toString(rep(term, count))) %&gt;% 
    select(document,terms) %&gt;% 
    unique()
}

final = topTerms(res) %&gt;% 
  mutate(term = reorder(term, beta)) %&gt;%
  ggplot(aes(term, beta, fill = factor(topic))) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~ topic, scales = &quot;free&quot;) + 
  labs(x = NULL, y = &quot;Beta&quot;) +  
  coord_flip()</code></pre>
<pre><code>## Warning in tm_map.SimpleCorpus(., tolower): transformation drops documents</code></pre>
<pre><code>## Warning in tm_map.SimpleCorpus(., removePunctuation): transformation drops
## documents</code></pre>
<pre><code>## Warning in tm_map.SimpleCorpus(., removeNumbers): transformation drops documents</code></pre>
<pre><code>## Warning in tm_map.SimpleCorpus(., removeWords, stopwords(&quot;english&quot;)):
## transformation drops documents</code></pre>
<pre class="r"><code>final</code></pre>
<p><img src="/post/2020-04-22-escola-isis-de-radicalizacao-religiosa-uma-analise-com-nlp_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Ok, temos algo melhor. Observando os gráficos na ordem, podemos ter ideia do que cada um dos 4 tópicos abordam, porém não temos nenhuma surpresa advinda deste dataset. Todos nós temos nossos conhecimentos de grupos terroristas, sabemos muito bem como o discurso funciona, devido ao nosso extenso aprendizado com Call of Duty e filmes americanos.</p>
<p>No terceiro, as mensagens tem relação mais intima com assuntos estritamente religiosos. Palavras como <code>Allah, messenger, prophet</code> são de cunho religioso, o que indica que provavelmente esses textos estariam classificados como “Quran”, no dataset. Também mostra que é possível traçar uma distinção entre textos que tratam exclusivamente de religião, é possível acreditar que, por serem textos utilizados por grupos terroristas, estejam relacionados a uma suposta glória da causa.</p>
<p>Em segundo lugar, temos, também, uma infinidade de termos religiosos. Atenção nas palavras <code>people, security, syrian, isis, iraq, jihd (jihad)</code>. Por esses termos, podemos imaginar que aqui o tema deixa de ser estritamente a religião, e passa a ser as motivações religiosas que são usadas como desculpa para o fazer a guerra, com especial foco à Síria.</p>
<p>Na primeira coluna, temos palavras importantes, dando destaque à <code>attawbah</code>, esta é a nona Surata do Alcorão, e trata de reparação e trata do balanço e dos problemas da harmonia e da guerra. O grupo de documentos parece ter relação com o sacrificio necessário pela guerra.</p>
<div id="conclusão" class="section level3">
<h3>Conclusão</h3>
<p>No fim, concluo que talvez usar o LDA nesse grupo de documentos não tenha sido a melhor escolha. Voltarei a este dataset no futuro, porém, talvez usando TF-IDF para fazer a análise, espero ter resultados mais satisfatórios. O fato de todos os textos possuirem uma densa carga de discurso religioso pode ter atrapalhado os resultados do modelo, o tamanho dos textos também é um problema, o LDA performa mal em textos curtos. Fica o aprendizado.</p>
</div>
